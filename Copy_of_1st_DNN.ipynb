{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 1st DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/immidikalipradeep/EIP4/blob/master/Copy_of_1st_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "f451d5bc-b5b2-424b-eb6c-22d982a66e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "f03e9a08-cf3c-434f-d79d-0d5143ceb48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "6267cabd-1841-4a60-c7b7-5dcb0a1ad09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0],cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6451fdab70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "82067e78-4f8a-47ba-82ce-69800c5351f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "c79dcb6d-1bea-40ae-f2f1-8f81a78d5acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqc6uNQE5slw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "77a1391d-4732-4293-be71-dd06e71fbe7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 1, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Convolution2D(10, 13))\n",
        "\n",
        "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "\n",
        "#model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "#model.add(Convolution2D(28, kernel_size=(3,3), input_shape=(28, 28, 1)))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "#model.add(Dense(128, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "c3d5d433-0003-452d-f25c-a4aec0ed96f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_83 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 26, 26, 32)        1056      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 1, 1, 10)          54090     \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 56,820\n",
            "Trainable params: 56,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "3c3880f2-71ce-490e-802b-58a05fa3748d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  800/60000 [..............................] - ETA: 13s - loss: 0.0410 - acc: 0.9825"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0442 - acc: 0.9857\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0459 - acc: 0.9848\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0451 - acc: 0.9856\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0432 - acc: 0.9865\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0438 - acc: 0.9860\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0445 - acc: 0.9852\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0426 - acc: 0.9867\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 0.0426 - acc: 0.9865\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0444 - acc: 0.9857\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0416 - acc: 0.9865\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0461 - acc: 0.9852\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0405 - acc: 0.9870\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0420 - acc: 0.9865\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0424 - acc: 0.9864\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 0.0423 - acc: 0.9866\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0417 - acc: 0.9871\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 0.0423 - acc: 0.9864\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0439 - acc: 0.9860\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0384 - acc: 0.9872\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0429 - acc: 0.9860\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0395 - acc: 0.9869\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0431 - acc: 0.9863\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.0411 - acc: 0.9867\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0397 - acc: 0.9868\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0403 - acc: 0.9870\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0393 - acc: 0.9872\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0404 - acc: 0.9872\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0391 - acc: 0.9873\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0416 - acc: 0.9869\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0392 - acc: 0.9873\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0417 - acc: 0.9863\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0393 - acc: 0.9875\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0390 - acc: 0.9871\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0378 - acc: 0.9877\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0393 - acc: 0.9872\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0399 - acc: 0.9869\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0381 - acc: 0.9874\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0386 - acc: 0.9875\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0389 - acc: 0.9875\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0384 - acc: 0.9875\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0383 - acc: 0.9875\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0383 - acc: 0.9876\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0378 - acc: 0.9877\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0377 - acc: 0.9879\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0366 - acc: 0.9882\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0377 - acc: 0.9877\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0369 - acc: 0.9879\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0369 - acc: 0.9881\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0389 - acc: 0.9878\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0359 - acc: 0.9886\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0374 - acc: 0.9879\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0371 - acc: 0.9877\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0372 - acc: 0.9883\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0360 - acc: 0.9879\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0405 - acc: 0.9868\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0388 - acc: 0.9874\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0363 - acc: 0.9879\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0387 - acc: 0.9876\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0369 - acc: 0.9882\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.0381 - acc: 0.9874\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0352 - acc: 0.9881\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0367 - acc: 0.9882\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0374 - acc: 0.9883\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0370 - acc: 0.9881\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0336 - acc: 0.9892\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0366 - acc: 0.9884\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0364 - acc: 0.9883\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0367 - acc: 0.9881\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0362 - acc: 0.9884\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0375 - acc: 0.9879\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0364 - acc: 0.9882\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0384 - acc: 0.9879\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0342 - acc: 0.9887\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0378 - acc: 0.9879\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0366 - acc: 0.9877\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0355 - acc: 0.9887\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0351 - acc: 0.9890\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0353 - acc: 0.9880\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0348 - acc: 0.9886\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0360 - acc: 0.9884\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0345 - acc: 0.9889\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0347 - acc: 0.9889\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0359 - acc: 0.9883\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0365 - acc: 0.9878\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0353 - acc: 0.9883\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0343 - acc: 0.9892\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0352 - acc: 0.9887\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0379 - acc: 0.9882\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0341 - acc: 0.9886\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0355 - acc: 0.9887\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0366 - acc: 0.9882\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0333 - acc: 0.9885\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.0347 - acc: 0.9889\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0369 - acc: 0.9884\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0333 - acc: 0.9890\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0337 - acc: 0.9888\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0361 - acc: 0.9882\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0336 - acc: 0.9894\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 0.0345 - acc: 0.9881\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 0.0357 - acc: 0.9881\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f641b3ca550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "outputId": "8b01adec-be2c-4a93-dd6f-4c3574fa50b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 71us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "a11746a1-9446-4a7e-a018-ca345b6343eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03659808676887187, 0.9912]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_14'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}